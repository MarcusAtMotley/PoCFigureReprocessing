/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    PoC Figure Reprocessing - AWS Batch Configuration
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Configuration for running the pipeline on AWS Batch.

    Prerequisites:
    - AWS Batch compute environment and job queue configured
    - S3 bucket for work directory and results
    - IAM roles with appropriate permissions

    Usage:
        nextflow run pipelines/main.nf -profile awsbatch \
            --input s3://bucket/samplesheet.csv \
            --outdir s3://motleybio/PoC_Reprocessing \
            --aws_queue your-batch-queue-name \
            -w s3://motleybio/PoC_Reprocessing/work
----------------------------------------------------------------------------------------
*/

params {
    config_profile_name        = 'AWS Batch profile'
    config_profile_description = 'Configuration for running PoC pipelines on AWS Batch'
}

process {
    // Use AWS Batch executor
    executor = 'awsbatch'

    // Batch queue - MUST be set via --aws_queue parameter
    queue = { params.aws_queue ?: error("AWS Batch queue not specified. Use --aws_queue parameter") }

    // Error handling for spot termination and transient failures
    errorStrategy = {
        task.exitStatus in [143,137,104,134,139,140] ? 'retry' :
        task.exitStatus == null ? 'retry' :
        task.attempt <= 2 ? 'retry' : 'finish'
    }
    maxRetries    = 2
    maxErrors     = '-1'

    // =========================================================================
    // Resource Labels for AWS Batch
    // =========================================================================

    withLabel: process_single {
        cpus   = 1
        memory = 4.GB
    }

    withLabel: process_low {
        cpus   = 2
        memory = 8.GB
    }

    withLabel: process_medium {
        cpus   = 8
        memory = 32.GB
    }

    withLabel: process_high {
        cpus   = 16
        memory = 60.GB
    }

    withLabel: process_long {
        cpus   = 4
        memory = 16.GB
        time   = 24.h
    }

    withLabel: process_high_memory {
        cpus   = 16
        memory = 60.GB
    }

    // =========================================================================
    // Process-Specific Overrides for AWS
    // =========================================================================

    withName: '.*TRIMGALORE.*' {
        cpus   = 4
        memory = 16.GB
    }

    withName: '.*BISCUIT_ALIGN.*' {
        cpus   = 8
        memory = 32.GB
    }

    withName: '.*BISCUIT_PILEUP.*' {
        cpus   = 4
        memory = 16.GB
    }

    withName: '.*STAR_ALIGN.*' {
        cpus   = 16
        memory = 60.GB
    }

    withName: '.*HISAT2_ALIGN.*' {
        cpus   = 8
        memory = 32.GB
    }

    withName: '.*LOFREQ.*' {
        cpus   = 8
        memory = 32.GB
    }

    withName: '.*FEATURECOUNTS.*' {
        cpus   = 4
        memory = 16.GB
    }

    withName: '.*CNVPYTOR.*' {
        cpus   = 4
        memory = 16.GB
    }

    withName: '.*SAMTOOLS.*' {
        cpus   = 4
        memory = 16.GB
    }
}

aws {
    // AWS region - set via params.aws_region or environment variable
    region = params.aws_region ?: System.getenv('AWS_DEFAULT_REGION') ?: 'us-east-2'

    batch {
        // Path to AWS CLI
        cliPath = '/usr/local/bin/aws'

        // Mount local NVMe to /tmp for LoFreq temp files
        // LoFreq has HARDCODED /tmp/ paths that ignore TMPDIR
        volumes = '/scratch/fusion:/tmp'

        // S3 transfer settings
        maxParallelTransfers = 4
        maxTransferAttempts = 3
        delayBetweenAttempts = '5 sec'
    }

    client {
        storageClass = 'STANDARD'
        maxConnections = 10
        connectionTimeout = 10000
        uploadStorageClass = 'INTELLIGENT_TIERING'
        uploadMaxThreads = 4
        uploadChunkSize = '100MB'
        uploadMaxAttempts = 3
        downloadMaxAttempts = 3
    }
}

// AWS Batch uses Docker containers
docker {
    enabled = true
    registry = 'quay.io'
}

// Enable Wave containers for automatic entrypoint handling
wave {
    enabled = true
    strategy = 'conda,container'
    freeze = true
}

// Report settings for AWS
trace {
    enabled = true
    overwrite = true
}

report {
    overwrite = true
}

timeline {
    overwrite = true
}
